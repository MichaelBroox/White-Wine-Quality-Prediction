{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AddictivePtyhon](AddictivePython.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vinho Verde White WINE QUALITY PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile train.py\n",
    "\n",
    "# Loading the iconic trio ðŸ”¥\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Importing model_selection to get access to some dope functions like GridSearchCV()\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "# Loading models\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "import xgboost\n",
    "from sklearn import linear_model\n",
    "\n",
    "# custom\n",
    "from custom import helper\n",
    "\n",
    "# Loading evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = pd.read_csv(\"data/preprocessed_data.csv\")\n",
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Copy of the Loaded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets = preprocessed_data.copy()\n",
    "data_with_targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping `quality` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_targets = data_with_targets.drop(['quality'], axis=1)\n",
    "data_with_targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into Feature Matrix and Target Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'quality_rate'\n",
    "\n",
    "# Unscaled Features\n",
    "X = data_with_targets.drop([target_variable], axis=1)\n",
    "\n",
    "# Target Variable\n",
    "y = data_with_targets[target_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE Sampling to deal with imbalance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Seed Value\n",
    "seed = 81\n",
    "\n",
    "smote = SVMSMOTE(random_state=seed)\n",
    "\n",
    "resampled_X, resampled_y = smote.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(resampled_X, resampled_y, test_size=0.3, stratify=resampled_y, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalling Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = list(X.columns.values)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "normalized_X_train = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train), \n",
    "    columns=column_names, \n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "\n",
    "normalized_X_test = pd.DataFrame(\n",
    "    scaler.transform(X_test), \n",
    "    columns=column_names, \n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating baseline models\n",
    "models = [\n",
    "    (\"Decision Tree\", tree.DecisionTreeClassifier(random_state=seed)),\n",
    "    (\"Random Forest\", ensemble.RandomForestClassifier(random_state=seed)),\n",
    "    (\"AdaBoost\", ensemble.AdaBoostClassifier(random_state=seed)),\n",
    "    (\"ExtraTree\", ensemble.ExtraTreesClassifier(random_state=seed)),\n",
    "    (\"GradientBoosting\", ensemble.GradientBoostingClassifier(random_state=seed)),\n",
    "    (\"XGBOOST\", xgboost.XGBClassifier(random_state=seed)),\n",
    "]\n",
    "\n",
    "feature_importance_of_models, df_model_features_with_importance, model_summary = helper.baseline_performance(\n",
    "    models=models, \n",
    "    X_train=normalized_X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=normalized_X_test, \n",
    "    y_test=y_test, \n",
    "    column_names=list(X.columns.values), \n",
    "    csv_path='csv_tables', \n",
    "    save_model_summary=True, \n",
    "    save_feature_importance=True, \n",
    "    save_feature_imp_of_each_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Train and Test Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_model_summary(\n",
    "    model_summary=model_summary, \n",
    "    figsize=(20, 14), \n",
    "    dpi=600, \n",
    "    transparent=True,\n",
    "    save_visualization=True, \n",
    "    figure_name='Train and Test Accuracies', \n",
    "    figure_path='figures',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_feature_importance(\n",
    "    df_model_features_with_importance, \n",
    "    figsize=(20, 15), \n",
    "    dpi=600, \n",
    "    transparent=True,\n",
    "    annotate_fontsize='xx-large',\n",
    "    save_plot=True,\n",
    "    path='figures',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Top 6 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_6_features = list(feature_importance_of_models['GradientBoosting'].head(6))\n",
    "top_6_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X_train_new = normalized_X_train[top_6_features]\n",
    "normalized_X_train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X_test_new = normalized_X_test[top_6_features]\n",
    "normalized_X_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new, X_test_new, y_train_new, y_test_new = model_selection.train_test_split(X_new, y, test_size=0.2, stratify=y, random_state=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating New Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.create_folder('./new_csv_tables/')\n",
    "helper.create_folder('./new_figures/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling on Top 6 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_of_models_new, model_features_with_importance_new, model_summary_new = helper.baseline_performance(\n",
    "    models=models, \n",
    "    X_train=normalized_X_train_new, \n",
    "    y_train=y_train, \n",
    "    X_test=normalized_X_test_new, \n",
    "    y_test=y_test, \n",
    "    column_names=list(top_6_features), \n",
    "    csv_path='new_csv_tables', \n",
    "    save_model_summary=True, \n",
    "    save_feature_importance=True, \n",
    "    save_feature_imp_of_each_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Train and Test Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_model_summary(\n",
    "    model_summary=model_summary_new, \n",
    "    figsize=(20, 14), \n",
    "    dpi=300, \n",
    "    transparent=True,\n",
    "    save_visualization=True, \n",
    "    figure_name='Train and Test Accuracies_new', \n",
    "    figure_path='new_figures',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_feature_importance(\n",
    "    feature_importance=model_features_with_importance_new, \n",
    "    figsize=(20, 14), \n",
    "    dpi=600, \n",
    "    transparent=True,\n",
    "    annotate_fontsize='xx-large',\n",
    "    save_plot=True,\n",
    "    path='new_figures',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into 10 folds\n",
    "cv_kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=150)\n",
    "\n",
    "scorer = \"f1\"\n",
    "\n",
    "# Instantiating model_names as an empty list to keep the names of the models\n",
    "model_names = []\n",
    "\n",
    "# Instantiating cv_mean_scores as an empty list to keep the cross validation mean score of each model\n",
    "cv_mean_scores = []\n",
    "\n",
    "# Instantiating cv_std_scores as an empty list to keep the cross validation standard deviation score of each model\n",
    "cv_std_scores = []\n",
    "\n",
    "# Looping through the baseline models and cross validating each model\n",
    "for model_name, model in models:\n",
    "    model_scores = model_selection.cross_val_score(\n",
    "        model, X, y, cv=cv_kfold, scoring=scorer, n_jobs=-1, verbose=1,\n",
    "    )\n",
    "    \n",
    "    print(\n",
    "        f\"{model_name} Score: %0.2f (+/- %0.2f)\"\n",
    "        % (model_scores.mean(), model_scores.std() * 2)\n",
    "    )\n",
    "\n",
    "    # Appending model names to model_name\n",
    "    model_names.append(model_name)\n",
    "    \n",
    "    # Appending cross validation mean score of each model to cv_mean_score\n",
    "    cv_mean_scores.append(model_scores.mean())\n",
    "    \n",
    "    # Appending cross validation standard deviation score of each model to cv_std_score\n",
    "    cv_std_scores.append(model_scores.std())\n",
    "\n",
    "\n",
    "# Parsing model_names, cv_mean_scores and cv_std_scores and a pandas DataFrame object\n",
    "cv_results = pd.DataFrame({\"model_name\": model_names, \"mean_score\": cv_mean_scores, \"std_score\": cv_std_scores})\n",
    "\n",
    "# Sorting the Dataframe in descending order\n",
    "cv_results.sort_values(\"mean_score\", ascending=False, inplace=True,)\n",
    "\n",
    "# Saving the DataFrame as a csv file\n",
    "cv_results.to_csv(\"csv_tables/cross_validation_results.csv\", index=True)\n",
    "\n",
    "# Showing the final results\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Classifier to Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = models[2][1]\n",
    "    \n",
    "classifier = models[4][1]\n",
    "\n",
    "classifier.fit(normalized_X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Train and Test Accuracy of the Choosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = classifier.score(normalized_X_train_new, y_train)\n",
    "\n",
    "test_accuracy = classifier.score(normalized_X_test_new, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.evaluate_classifier(\n",
    "    estimator=classifier, \n",
    "    X_test=normalized_X_test_new, \n",
    "    y_test=y_test,\n",
    "    save_figure=True,\n",
    "    figure_path='figures',\n",
    "    transparent=True, \n",
    "    dpi=600,\n",
    "    cmap=\"Purples\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
